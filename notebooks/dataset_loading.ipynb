{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0602df",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf16dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:56:34.027400Z",
     "start_time": "2022-03-14T16:56:34.019062Z"
    }
   },
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import emoji\n",
    "import unicodedata as ud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f596b89",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be5ed5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:56:31.153101Z",
     "start_time": "2022-03-14T16:56:31.131116Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_chunks(reader:csv.reader, chunksize:int=1000)->list:\n",
    "    \"\"\"yeilds data as cuncks of size 1000 to feed it to the aiohttp library to make requests\n",
    "\n",
    "    Args:\n",
    "        reader (csv.reader): a reader object to read the csv\n",
    "        chunksize (int, optional): the size that should be read for each iteration. Defaults to 1000.\n",
    "\n",
    "    Yields:\n",
    "        Iterator[list]: a chunck to be processed\n",
    "    \"\"\"   \n",
    "    chunk = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if (i % chunksize == 0 and i > 0):\n",
    "            yield chunk\n",
    "            del chunk[:]  # or: chunk = []\n",
    "        chunk.append(row)\n",
    "    yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f06c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:50:45.938345Z",
     "start_time": "2022-03-12T00:50:45.926142Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_tweet(tweet:str)->str:\n",
    "        \"\"\"filters the tweet from every unwanted token\n",
    "\n",
    "        Args:\n",
    "                tweet (str): a text containing all the tweet\n",
    "\n",
    "        Returns:\n",
    "                str: the filtered tweet\n",
    "        \"\"\"  \n",
    "        # a list of all arabic flags, as we want to keep them only and remove any other flag      \n",
    "        flags={'U+1F1E6',\n",
    "                'U+1F1E7',\n",
    "                'U+1F1E9',\n",
    "                'U+1F1EA',\n",
    "                'U+1F1EC',\n",
    "                'U+1F1ED',\n",
    "                'U+1F1EE',\n",
    "                'U+1F1EF',\n",
    "                'U+1F1F0',\n",
    "                'U+1F1F1',\n",
    "                'U+1F1F2',\n",
    "                'U+1F1F3',\n",
    "                'U+1F1F4',\n",
    "                'U+1F1F5',\n",
    "                'U+1F1F6',\n",
    "                'U+1F1F7',\n",
    "                'U+1F1F8',\n",
    "                'U+1F1F9',\n",
    "                'U+1F1FC',\n",
    "                'U+1F1FE',\n",
    "                'U+1F1FF'}\n",
    "\n",
    "        # remove emojis except for flags\n",
    "        tweet  =''.join(char for char in tweet if (char in flags or not emoji.is_emoji(char)))\n",
    "        # remove mentions\n",
    "        tweet = re.sub(\"@[A-Za-z0-9_]+\", \"\", tweet)\n",
    "        # remove links\n",
    "        tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "        # remove hashes and keep the words\n",
    "        tweet = tweet.replace(\"#\", \" \").replace(\"_\", \" \")\n",
    "        # remove all english characters\n",
    "        tweet = re.sub('[a-zA-Z0-9]+', '', tweet)\n",
    "        # replace  multiple spaces with one space\n",
    "        tweet = re.sub(' +', ' ',tweet)\n",
    "        # remove all punctionations and all digits (arabic and english)\n",
    "        tweet  =''.join(char for char in tweet if not (\n",
    "                        ud.category(char).startswith('P') or \n",
    "                        ud.category(char).startswith('Nd')))\n",
    "        return tweet\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a866c31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:50:51.298991Z",
     "start_time": "2022-03-12T00:50:51.293373Z"
    }
   },
   "outputs": [],
   "source": [
    "async def process_chunks(session:aiohttp.ClientSession(), url:str, chunk:list)->list:\n",
    "    \"\"\"Takes chunk, and makes post request to the api, then it parses and filters it.\n",
    "\n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): An aiohttp client session to request the tweets from\n",
    "        url (str): the url of the API\n",
    "        chunk (list): a list containing all the ids to of the tweets to be retrieved\n",
    "\n",
    "    Returns:\n",
    "        list: a list of parsed and filtered reponse from the API\n",
    "    \"\"\"\n",
    "    chunk=dict(chunk)\n",
    "    ids = list(chunk.keys())\n",
    "    \n",
    "    response=await session.post(url, json=ids)\n",
    "    tweets = await response.json()\n",
    "    rows=[]\n",
    "    for  aid, tweet in tweets.items():\n",
    "        rows.append(\n",
    "        {\n",
    "            \"id\":aid,\n",
    "            \"tweet\": filter_tweet(tweet),\n",
    "            \"label\":chunk[aid]\n",
    "        })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325716f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:50:56.982559Z",
     "start_time": "2022-03-12T00:50:56.976436Z"
    }
   },
   "outputs": [],
   "source": [
    "async def download_data(reader:csv.reader,writer:csv.DictWriter)->list:\n",
    "    \"\"\"a function that calles the chunk generator and process the data then it saves it in a CSV file   \n",
    "\n",
    "    Args:\n",
    "        reader (csv.reader): A CSV reader object of the input CSV\n",
    "        writer (csv.DictWriter): A csv writer object for the output CSV\n",
    "\n",
    "    Returns:\n",
    "        list: a list of all the acquired output from the API\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "             \n",
    "        for chunk in tqdm(gen_chunks(reader, chunksize=1000),total=math.ceil(458198/1000)):\n",
    "            url = \"https://recruitment.aimtechnologies.co/ai-tasks\"\n",
    "\n",
    "            rows =  await process_chunks(session, url, chunk)\n",
    "            out.extend(rows)\n",
    "            writer.writerows(rows) \n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7217243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:54:24.938920Z",
     "start_time": "2022-03-12T00:51:03.554487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [09:48<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(open('../data/raw/dialect_dataset.csv', 'rt'))\n",
    "# getting the header first which contains the column labels\n",
    "next(reader)\n",
    "# defining the writer of the output file\n",
    "writer= csv.DictWriter(open('../data/interim/out.csv', 'w'),fieldnames=['id','tweet','label'],delimiter=\"|\") \n",
    "\n",
    "# writhing the column names\n",
    "writer.writeheader()\n",
    "\n",
    "# calling the function to download the data\n",
    "out=await download_data(reader,writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0775ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:54:25.358315Z",
     "start_time": "2022-03-12T00:54:25.172982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458197"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(out)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70caee20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T00:54:27.874913Z",
     "start_time": "2022-03-12T00:54:25.504739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>لكن بالنهاية  ينتفض  يغير</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>يعني هذا محسوب على البشر  حيونه ووحشيه  وتطلب...</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458178</th>\n",
       "      <td>1021088486915559424</td>\n",
       "      <td>مرو خذوني وياكم بالاحمر</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458179</th>\n",
       "      <td>1024943651569446784</td>\n",
       "      <td>هاي لو كنت حابه تاكلي شو طلبك</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458180</th>\n",
       "      <td>1018588912648904832</td>\n",
       "      <td>الحين نسوي ربيان مشوي حياكم</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458181</th>\n",
       "      <td>1024945458576273408</td>\n",
       "      <td>الله يغفر لكم\\nمساء الوررررد</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458182</th>\n",
       "      <td>1018270352013656064</td>\n",
       "      <td>يمكن تعرفين بخورة السوق امس او اليوم كانت حاط...</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0       1175358310087892992   \n",
       "1       1175416117793349632   \n",
       "2       1175450108898565888   \n",
       "3       1175471073770573824   \n",
       "4       1175496913145217024   \n",
       "...                     ...   \n",
       "458178  1021088486915559424   \n",
       "458179  1024943651569446784   \n",
       "458180  1018588912648904832   \n",
       "458181  1024945458576273408   \n",
       "458182  1018270352013656064   \n",
       "\n",
       "                                                    tweet label  \n",
       "0                              لكن بالنهاية  ينتفض  يغير     IQ  \n",
       "1        يعني هذا محسوب على البشر  حيونه ووحشيه  وتطلب...    IQ  \n",
       "2                                     مبين من كلامه خليجي    IQ  \n",
       "3                               يسلملي مرورك وروحك الحلوه    IQ  \n",
       "4                                  وين هل الغيبه اخ محمد     IQ  \n",
       "...                                                   ...   ...  \n",
       "458178                           مرو خذوني وياكم بالاحمر     BH  \n",
       "458179                      هاي لو كنت حابه تاكلي شو طلبك    BH  \n",
       "458180                        الحين نسوي ربيان مشوي حياكم    BH  \n",
       "458181                       الله يغفر لكم\\nمساء الوررررد    BH  \n",
       "458182   يمكن تعرفين بخورة السوق امس او اليوم كانت حاط...    BH  \n",
       "\n",
       "[458183 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/interim/out.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e8a6f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# scrap functions (not used in the code rather was used to find the best approach possible) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a20cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T21:39:25.148936Z",
     "start_time": "2022-03-10T21:39:20.448416Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "% % timeit\n",
    "\n",
    "for chunk in pd.read_csv(\"dialect_dataset.csv\", chunksize=1000):\n",
    "    #     print(chunk)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6ff2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6235d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T21:59:26.995252Z",
     "start_time": "2022-03-10T21:59:25.961833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "reader = csv.reader(open('dialect_dataset.csv', 'rt'))\n",
    "# getting the header first which contains the column labels\n",
    "header = next(reader)\n",
    "\n",
    "for chunk in gen_chunks(reader, chunksize=1000):\n",
    "    ids, labels = zip(*chunk)\n",
    "    url = \"https://recruitment.aimtechnologies.co/ai-tasks\"\n",
    "    response = process_chunks(url, ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f6a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T21:39:01.675198Z",
     "start_time": "2022-03-10T21:38:59.188301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%% timeit\n",
    "reader = csv.reader(open('dialect_dataset.csv', 'rt'))\n",
    "\n",
    "chunk, chunksize = [], 1000\n",
    "\n",
    "\n",
    "def process_chunk(chuck):\n",
    "    #     print len(chuck)\n",
    "    pass\n",
    "    # do something useful ...\n",
    "\n",
    "\n",
    "for i, line in enumerate(reader):\n",
    "    if (i % chunksize == 0 and i > 0):\n",
    "        process_chunk(chunk)\n",
    "        del chunk[:]  # or: chunk = []\n",
    "    chunk.append(line)\n",
    "\n",
    "# process the remainder\n",
    "process_chunk(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
